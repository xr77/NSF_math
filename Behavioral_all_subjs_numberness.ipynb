{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# First load in the data files \n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = [304,305,306,307,308,309,345,362,330,363,388,3106,3107,310,361,356,3101,3102,399,3122,364,318,352,393,346,3110,397,343,337,3123,312,3120,3112,311,331,396,313,3124,340,374,335,3113,3119,342,3125,3100,3114,366,365,385,327,3108,353,368,326,360,336,314,3117,382,325,390,398,391,334,380,3118,3105,378,386,358,324,3116,317,392,3103,371,384,3121,354,3115,341,350,377,369,348,394,3111,379,3126,3127,3128,3129,315,319,321,323,328,332,333,339,347,349,351,355,357,367,370,372,373,375,381,383,387,395,3104,3109]\n",
    "#304,305,306,307,308,309 were added, 117 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [01:28<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#results = []\n",
    "\n",
    "for i in tqdm(subj_list):\n",
    "    df = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/Sub{i}_numberness_2.csv\")\n",
    "    #print(i)\n",
    "    RT = df['RT']\n",
    "    RT = RT[(RT <10) * (RT>0.1)]  # to be consistent with ruizhi's R code calculation\n",
    "    RT_mean = RT.mean()\n",
    "    #print(f\"RT_mean={RT_mean}\")\n",
    "    RT_std = RT.std()\n",
    "    #print(f\"RT_std = {RT_std}\")   \n",
    "    \n",
    "    pic_id = df ['picID']\n",
    "    df ['match_type'] = pic_id.apply(lambda x: x.split('_')[0])# colums can't be split, should be applied to each element\n",
    "    \n",
    "    df ['pic_type'] = pic_id.apply(lambda x: x.split('_')[1])\n",
    "    \n",
    "    df ['Trial_type'] =  df ['pic_type'].apply(lambda x:1 if( x.isdigit()) else 2)\n",
    "    \n",
    "    #import pdb;pdb.set_trace()\n",
    "    \n",
    "    df['RT_corrected'] = df['RT'].apply(lambda x: x  if ( (x >= 0.2) and ((( x -RT_mean)/RT_std) <= 3)) else np.nan)# get rid of outliers beyond 3 std\n",
    "    #df[np.isnan(df['RT_corrected'])]['TrialID'] # The corresbonding Trial ID excluded. \n",
    "    \n",
    "    df.loc[df['Response'] == df['Trial_type'],'Acc'] = 1\n",
    "    df.loc[df['Response'] != df['Trial_type'],'Acc'] = 0\n",
    "    \n",
    "    df['Acc_corrected'] = df ['Acc']\n",
    "    df.loc[np.isnan(df['RT_corrected']),'Acc_corrected'] = np.nan # get rid of null values;np.isnan is right, not != np.nan\n",
    "    \n",
    "    df['RT_letter_match'] = df ['RT_corrected']\n",
    "    df.loc[(df['match_type'] != 'match') | (df['Trial_type']!= 2), 'RT_letter_match'] = np.nan\n",
    "    \n",
    "    df['RT_letter_mismatch'] = df ['RT_corrected']\n",
    "    df.loc[(df['match_type'] != 'mismatch') | (df['Trial_type']!= 2), 'RT_letter_mismatch'] = np.nan\n",
    "    \n",
    "    df['RT_number_match'] = df ['RT_corrected']\n",
    "    df.loc[(df['match_type'] != 'match') | (df['Trial_type']!= 1), 'RT_number_match'] = np.nan\n",
    "    \n",
    "    df['RT_number_mismatch'] = df ['RT_corrected']\n",
    "    df.loc[(df['match_type'] != 'mismatch') | (df['Trial_type']!= 1), 'RT_number_mismatch'] = np.nan\n",
    "    \n",
    "    df['Acc_letter_match'] = df ['Acc_corrected']\n",
    "    df.loc[(df['match_type'] != 'match') | (df['Trial_type']!= 2), 'Acc_letter_match'] = np.nan\n",
    "    \n",
    "    df['Acc_letter_mismatch'] = df ['Acc_corrected']\n",
    "    df.loc[(df['match_type'] != 'mismatch') | (df['Trial_type']!= 2), 'Acc_letter_mismatch'] = np.nan\n",
    "\n",
    "    df['Acc_number_match'] = df ['Acc_corrected']\n",
    "    df.loc[(df['match_type'] != 'match') | (df['Trial_type']!= 1), 'Acc_number_match'] = np.nan\n",
    "    \n",
    "    df['Acc_number_mismatch'] = df ['Acc_corrected']\n",
    "    df.loc[(df['match_type'] != 'mismatch') | (df['Trial_type']!= 1), 'Acc_number_mismatch'] = np.nan\n",
    "    \n",
    "    \n",
    "    df['TrialID_corrected'] = df ['TrialID']\n",
    "    df.loc[np.isnan(df['RT_corrected']),'TrialID_corrected'] = np.nan\n",
    "    \n",
    "    df.to_csv(f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_2_reorganized.csv\",index = False)\n",
    "    \n",
    "    #results_dict = {'SubjId': i,\n",
    "                    #'Trial_count': len(df[~np.isnan(df['TrialID_corrected'])]),\n",
    "                    #'RT_mean_overall': df['RT_corrected'].mean(), \n",
    "                    #'Acc_mean_overall': df['Acc_corrected'].mean(), \n",
    "                    #'RT_letter_match': df['RT_letter_match'].mean(),\n",
    "                    #'RT_letter_mismatch': df['RT_letter_mismatch'].mean(),\n",
    "                    #'Acc_letter_match': df['Acc_letter_match'].mean(),\n",
    "                    #'Acc_letter_mismatch': df['Acc_letter_mismatch'].mean(),\n",
    "                    #'TrialID_excluded': list(df[np.isnan(df['RT_corrected'])]['TrialID'])}\n",
    "    #results.append(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:44<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "#subj_list = [388]\n",
    "for i in tqdm(subj_list):\n",
    "    df_1 = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_1_reorganized.csv\")\n",
    "    #df_2 = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_2_reorganized.csv\")\n",
    "    #df_combined = df_1.append(df_2, ignore_index=True, sort=False)\n",
    "    #df_combined.to_csv(f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_reorganized_combined.csv\",index = False)\n",
    "    results_dict = {'SubjId': i,\n",
    "                    'Trial_count': len(df_1[~np.isnan(df_1['TrialID_corrected'])]),\n",
    "                    'RT_mean_overall': df_1['RT_corrected'].mean(), \n",
    "                    'Acc_mean_overall': df_1['Acc_corrected'].mean(), \n",
    "                    'RT_letter_match': df_1['RT_letter_match'].mean(),\n",
    "                    'RT_number_match': df_1['RT_number_match'].mean(),\n",
    "                    'RT_letter_mismatch': df_1['RT_letter_mismatch'].mean(),\n",
    "                    'RT_number_mismatch': df_1['RT_number_mismatch'].mean(),\n",
    "                    'Acc_letter_match': df_1['Acc_letter_match'].mean(),\n",
    "                    'Acc_number_match': df_1['Acc_number_match'].mean(),\n",
    "                    'Acc_letter_mismatch': df_1['Acc_letter_mismatch'].mean(),\n",
    "                    'Acc_number_mismatch': df_1['Acc_number_mismatch'].mean(),\n",
    "                    'TrialID_excluded': list(df_1[np.isnan(df_1['RT_corrected'])]['TrialID'])}\n",
    "    results.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resutls = pd.DataFrame(results)\n",
    "data_resutls.to_csv ('/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks/all_subjs_numberness_session1.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:46<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "#subj_list = [388]\n",
    "for i in tqdm(subj_list):\n",
    "    #df_1 = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_1_reorganized.csv\")\n",
    "    df_2 = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_2_reorganized.csv\")\n",
    "    #df_combined = df_1.append(df_2, ignore_index=True, sort=False)\n",
    "    #df_combined.to_csv(f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_reorganized_combined.csv\",index = False)\n",
    "    results_dict = {'SubjId': i,\n",
    "                    'Trial_count': len(df_2[~np.isnan(df_2['TrialID_corrected'])]),\n",
    "                    'RT_mean_overall': df_2['RT_corrected'].mean(), \n",
    "                    'Acc_mean_overall': df_2['Acc_corrected'].mean(), \n",
    "                    'RT_letter_match': df_2['RT_letter_match'].mean(),\n",
    "                    'RT_number_match': df_2['RT_number_match'].mean(),\n",
    "                    'RT_letter_mismatch': df_2['RT_letter_mismatch'].mean(),\n",
    "                    'RT_number_mismatch': df_2['RT_number_mismatch'].mean(),\n",
    "                    'Acc_letter_match': df_2['Acc_letter_match'].mean(),\n",
    "                    'Acc_number_match': df_2['Acc_number_match'].mean(),\n",
    "                    'Acc_letter_mismatch': df_2['Acc_letter_mismatch'].mean(),\n",
    "                    'Acc_number_mismatch': df_2['Acc_number_mismatch'].mean(),\n",
    "                    'TrialID_excluded': list(df_2[np.isnan(df_2['RT_corrected'])]['TrialID'])}\n",
    "    results.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resutls = pd.DataFrame(results)\n",
    "data_resutls.to_csv ('/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks/all_subjs_numberness_session2.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two session combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 94/117 [01:15<00:16,  1.37it/s]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "#subj_list = [388]\n",
    "for i in tqdm(subj_list):\n",
    "    df_1 = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_1_reorganized.csv\")\n",
    "    df_2 = pd.read_csv (f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_2_reorganized.csv\")\n",
    "    df_combined = df_1.append(df_2, ignore_index=True, sort=False)\n",
    "    df_combined.to_csv(f\"/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks//s{i}/s{i}_numberness_reorganized_combined.csv\",index = False)\n",
    "    results_dict = {'SubjId': i,\n",
    "                    'Trial_count': len(df_combined[~np.isnan(df_combined['TrialID_corrected'])]),\n",
    "                    'RT_mean_overall': df_combined['RT_corrected'].mean(), \n",
    "                    'Acc_mean_overall': df_combined['Acc_corrected'].mean(), \n",
    "                    'RT_letter_match': df_combined['RT_letter_match'].mean(),\n",
    "                    'RT_number_match': df_combined['RT_number_match'].mean(),\n",
    "                    'RT_letter_mismatch': df_combined['RT_letter_mismatch'].mean(),\n",
    "                    'RT_number_mismatch': df_combined['RT_number_mismatch'].mean(),\n",
    "                    'Acc_letter_match': df_combined['Acc_letter_match'].mean(),\n",
    "                    'Acc_number_match': df_combined['Acc_number_match'].mean(),\n",
    "                    'Acc_letter_mismatch': df_combined['Acc_letter_mismatch'].mean(),\n",
    "                    'Acc_number_mismatch': df_combined['Acc_number_mismatch'].mean(),\n",
    "                    'TrialID_excluded': list(df_combined[np.isnan(df_combined['RT_corrected'])]['TrialID'])}\n",
    "    results.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resutls = pd.DataFrame(results)\n",
    "data_resutls.to_csv ('/Volumes/project/NSFMath/Main/Behavioral_Task_Data/Computer_tasks/all_subjs_numberness_final.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
